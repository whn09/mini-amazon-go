{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  测试目标检测性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gluoncv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gluoncv as gcv\n",
    "import mxnet as mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_names: ['cocacola', 'noodles', 'hand', 'fake']\n",
      "num_images: 149\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "class DetectionDataset(gcv.data.VOCDetection):\n",
    "    CLASSES = ['cocacola', 'noodles', 'hand', 'fake']  # Yolo3 need at least 4 classes (https://github.com/apache/incubator-mxnet/pull/17689/files)\n",
    "    def __init__(self, root):\n",
    "        self._im_shapes = {}\n",
    "        self._root = os.path.expanduser(root)\n",
    "        self._transform = None\n",
    "        self._items = [(self._root, x.strip('.jpg')) for x in os.listdir(self._root) if x.endswith('.jpg')]\n",
    "        self._anno_path = os.path.join('{}', '{}.xml')\n",
    "        self._image_path = os.path.join('{}', '{}.jpg')\n",
    "        self.index_map = dict(zip(self.classes, range(self.num_class)))\n",
    "        self._label_cache = self._preload_labels()\n",
    "        \n",
    "    def __str__(self):\n",
    "        detail = self._root\n",
    "        return self.__class__.__name__ + '(' + detail + ')'\n",
    "    \n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self.CLASSES\n",
    "    \n",
    "    @property\n",
    "    def num_class(self):\n",
    "        return len(self.classes)\n",
    "    \n",
    "    def get_image_list(self):\n",
    "        return [os.path.join(x[0], x[1] + '.jpg') for x in self._items]\n",
    "        \n",
    "test_dataset = DetectionDataset('../images/shenzhen_v1')\n",
    "print('class_names:', test_dataset.classes)\n",
    "print('num_images:', len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 载入训练好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "磁盘上有训练好的模型： ['object_detector_epoch200_11_05_2020_16_58_31.params']\n",
      "载入完毕: object_detector_epoch200_11_05_2020_16_58_31.params\n"
     ]
    }
   ],
   "source": [
    "net = gcv.model_zoo.get_model('yolo3_darknet53_custom', classes=test_dataset.classes, pretrained_base=False)\n",
    "param_files = ([x for x in os.listdir('.') if x.endswith('.params')])\n",
    "selected = param_files[0]\n",
    "print('磁盘上有训练好的模型：', param_files)\n",
    "net.load_parameters(selected)\n",
    "print('载入完毕:', selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 观察检测性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试图像集： ['../images/shenzhen_v1/frame_1604547918.0878625.jpg', '../images/shenzhen_v1/frame_1604547990.0257223.jpg', '../images/shenzhen_v1/frame_1604547928.366902.jpg', '../images/shenzhen_v1/frame_1604547862.5851333.jpg', '../images/shenzhen_v1/frame_1604547908.8368647.jpg', '../images/shenzhen_v1/frame_1604557258.0419793.jpg', '../images/shenzhen_v1/frame_1604547889.3031857.jpg', '../images/shenzhen_v1/frame_1604547887.2466564.jpg', '../images/shenzhen_v1/frame_1604547868.7498348.jpg', '../images/shenzhen_v1/frame_1604557267.292567.jpg', '../images/shenzhen_v1/frame_1604547890.3314555.jpg', '../images/shenzhen_v1/frame_1604547944.8149817.jpg', '../images/shenzhen_v1/frame_1604547910.89245.jpg', '../images/shenzhen_v1/frame_1604547885.190378.jpg', '../images/shenzhen_v1/frame_1604547937.6198292.jpg', '../images/shenzhen_v1/frame_1604557269.347707.jpg', '../images/shenzhen_v1/frame_1604557268.3202035.jpg', '../images/shenzhen_v1/frame_1604547903.6937695.jpg', '../images/shenzhen_v1/frame_1604547860.5304892.jpg', '../images/shenzhen_v1/frame_1604547857.445723.jpg', '../images/shenzhen_v1/frame_1604547965.371091.jpg', '../images/shenzhen_v1/frame_1604547994.135967.jpg', '../images/shenzhen_v1/frame_1604547976.6725118.jpg', '../images/shenzhen_v1/frame_1604547957.1508708.jpg', '../images/shenzhen_v1/frame_1604557265.2366192.jpg', '../images/shenzhen_v1/frame_1604547961.2601466.jpg', '../images/shenzhen_v1/frame_1604557252.9006867.jpg', '../images/shenzhen_v1/frame_1604547869.777234.jpg', '../images/shenzhen_v1/frame_1604557261.1254058.jpg', '../images/shenzhen_v1/frame_1604547945.8437014.jpg', '../images/shenzhen_v1/frame_1604547926.310847.jpg', '../images/shenzhen_v1/frame_1604557248.7920978.jpg', '../images/shenzhen_v1/frame_1604547978.726913.jpg', '../images/shenzhen_v1/frame_1604547956.1240287.jpg', '../images/shenzhen_v1/frame_1604547875.9402676.jpg', '../images/shenzhen_v1/frame_1604547995.1682215.jpg', '../images/shenzhen_v1/frame_1604557254.9573805.jpg', '../images/shenzhen_v1/frame_1604547902.6656635.jpg', '../images/shenzhen_v1/frame_1604557249.8181102.jpg', '../images/shenzhen_v1/frame_1604557266.2646132.jpg', '../images/shenzhen_v1/frame_1604547899.5812564.jpg', '../images/shenzhen_v1/frame_1604547921.1703272.jpg', '../images/shenzhen_v1/frame_1604547982.8360722.jpg', '../images/shenzhen_v1/frame_1604547871.8323994.jpg', '../images/shenzhen_v1/frame_1604547917.0581176.jpg', '../images/shenzhen_v1/frame_1604547939.6766162.jpg', '../images/shenzhen_v1/frame_1604547922.1983647.jpg', '../images/shenzhen_v1/frame_1604547892.3865218.jpg', '../images/shenzhen_v1/frame_1604547953.041692.jpg', '../images/shenzhen_v1/frame_1604547893.414526.jpg', '../images/shenzhen_v1/frame_1604547906.777072.jpg', '../images/shenzhen_v1/frame_1604547866.6960037.jpg', '../images/shenzhen_v1/frame_1604547859.5024173.jpg', '../images/shenzhen_v1/frame_1604557250.8454032.jpg', '../images/shenzhen_v1/frame_1604547960.2332785.jpg', '../images/shenzhen_v1/frame_1604547941.7315683.jpg', '../images/shenzhen_v1/frame_1604547931.4511387.jpg', '../images/shenzhen_v1/frame_1604557251.872284.jpg', '../images/shenzhen_v1/frame_1604547963.3149285.jpg', '../images/shenzhen_v1/frame_1604547964.3431191.jpg', '../images/shenzhen_v1/frame_1604547942.7600105.jpg', '../images/shenzhen_v1/frame_1604547895.4705567.jpg', '../images/shenzhen_v1/frame_1604557257.0122123.jpg', '../images/shenzhen_v1/frame_1604547977.7001088.jpg', '../images/shenzhen_v1/frame_1604547898.5533266.jpg', '../images/shenzhen_v1/frame_1604547993.108556.jpg', '../images/shenzhen_v1/frame_1604547865.667732.jpg', '../images/shenzhen_v1/frame_1604547861.5574017.jpg', '../images/shenzhen_v1/frame_1604557273.4562168.jpg', '../images/shenzhen_v1/frame_1604547901.637496.jpg', '../images/shenzhen_v1/frame_1604547947.9013798.jpg', '../images/shenzhen_v1/frame_1604547983.8630676.jpg', '../images/shenzhen_v1/frame_1604547949.957794.jpg', '../images/shenzhen_v1/frame_1604547882.1081126.jpg', '../images/shenzhen_v1/frame_1604557271.4016595.jpg', '../images/shenzhen_v1/frame_1604547969.4821455.jpg', '../images/shenzhen_v1/frame_1604547970.509096.jpg', '../images/shenzhen_v1/frame_1604557263.1804109.jpg', '../images/shenzhen_v1/frame_1604547954.0691996.jpg', '../images/shenzhen_v1/frame_1604547916.03108.jpg', '../images/shenzhen_v1/frame_1604547907.8084173.jpg', '../images/shenzhen_v1/frame_1604547870.8048537.jpg', '../images/shenzhen_v1/frame_1604557262.1531785.jpg', '../images/shenzhen_v1/frame_1604547853.334592.jpg', '../images/shenzhen_v1/frame_1604547971.5365856.jpg', '../images/shenzhen_v1/frame_1604547909.8648596.jpg', '../images/shenzhen_v1/frame_1604547896.4978595.jpg', '../images/shenzhen_v1/frame_1604557247.7647603.jpg', '../images/shenzhen_v1/frame_1604547852.3077297.jpg', '../images/shenzhen_v1/frame_1604547962.2874782.jpg', '../images/shenzhen_v1/frame_1604557253.9292312.jpg', '../images/shenzhen_v1/frame_1604547920.1417084.jpg', '../images/shenzhen_v1/frame_1604547948.9298038.jpg', '../images/shenzhen_v1/frame_1604547991.0529857.jpg', '../images/shenzhen_v1/frame_1604547855.389591.jpg', '../images/shenzhen_v1/frame_1604547938.6486456.jpg', '../images/shenzhen_v1/frame_1604547856.4169474.jpg', '../images/shenzhen_v1/frame_1604547933.5082517.jpg', '../images/shenzhen_v1/frame_1604547955.097076.jpg', '../images/shenzhen_v1/frame_1604547873.8856199.jpg', '../images/shenzhen_v1/frame_1604547968.4544387.jpg', '../images/shenzhen_v1/frame_1604547905.7503836.jpg', '../images/shenzhen_v1/frame_1604557260.097172.jpg', '../images/shenzhen_v1/frame_1604547881.0802543.jpg', '../images/shenzhen_v1/frame_1604547950.984879.jpg', '../images/shenzhen_v1/frame_1604557270.3746116.jpg', '../images/shenzhen_v1/frame_1604547975.6455166.jpg', '../images/shenzhen_v1/frame_1604547952.0130267.jpg', '../images/shenzhen_v1/frame_1604547996.1991887.jpg', '../images/shenzhen_v1/frame_1604547894.4426997.jpg', '../images/shenzhen_v1/frame_1604547935.5634189.jpg', '../images/shenzhen_v1/frame_1604547883.135316.jpg', '../images/shenzhen_v1/frame_1604547897.5260258.jpg', '../images/shenzhen_v1/frame_1604547927.3387895.jpg', '../images/shenzhen_v1/frame_1604547932.4792564.jpg', '../images/shenzhen_v1/frame_1604547924.2542.jpg', '../images/shenzhen_v1/frame_1604547863.6124408.jpg', '../images/shenzhen_v1/frame_1604547884.1627853.jpg', '../images/shenzhen_v1/frame_1604547936.591463.jpg', '../images/shenzhen_v1/frame_1604547880.051009.jpg', '../images/shenzhen_v1/frame_1604557272.4284549.jpg', '../images/shenzhen_v1/frame_1604547940.7047036.jpg', '../images/shenzhen_v1/frame_1604557255.9850838.jpg', '../images/shenzhen_v1/frame_1604547943.7876813.jpg', '../images/shenzhen_v1/frame_1604547925.2816646.jpg', '../images/shenzhen_v1/frame_1604547854.3620293.jpg', '../images/shenzhen_v1/frame_1604547919.1143074.jpg', '../images/shenzhen_v1/frame_1604547888.275054.jpg', '../images/shenzhen_v1/frame_1604547929.3951433.jpg', '../images/shenzhen_v1/frame_1604547891.358371.jpg', '../images/shenzhen_v1/frame_1604547998.2576504.jpg', '../images/shenzhen_v1/frame_1604547988.9986818.jpg', '../images/shenzhen_v1/frame_1604547904.7223375.jpg', '../images/shenzhen_v1/frame_1604547930.4235425.jpg', '../images/shenzhen_v1/frame_1604547900.609367.jpg', '../images/shenzhen_v1/frame_1604557264.2081428.jpg', '../images/shenzhen_v1/frame_1604547858.4740584.jpg', '../images/shenzhen_v1/frame_1604547886.2183042.jpg', '../images/shenzhen_v1/frame_1604547872.859.jpg', '../images/shenzhen_v1/frame_1604547867.7232847.jpg', '../images/shenzhen_v1/frame_1604547992.0804336.jpg', '../images/shenzhen_v1/frame_1604547864.6397486.jpg', '../images/shenzhen_v1/frame_1604557259.0694675.jpg', '../images/shenzhen_v1/frame_1604547946.8734.jpg', '../images/shenzhen_v1/frame_1604547874.9131923.jpg', '../images/shenzhen_v1/frame_1604547997.2270377.jpg', '../images/shenzhen_v1/frame_1604547923.2260234.jpg', '../images/shenzhen_v1/frame_1604547934.536544.jpg', '../images/shenzhen_v1/frame_1604547987.9708455.jpg']\n"
     ]
    }
   ],
   "source": [
    "images = test_dataset.get_image_list()\n",
    "print('测试图像集：', images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from matplotlib import pyplot as plt\n",
    "# Use GPU\n",
    "ctx = mx.gpu(0)\n",
    "# ctx = mx.cpu(0)\n",
    "net.collect_params().reset_ctx(ctx)\n",
    "for image in images:\n",
    "    x, img = gcv.data.transforms.presets.yolo.load_test(image, short=512)\n",
    "    class_IDs, scores, bounding_boxes = net(x.as_in_context(ctx))\n",
    "    ax = gcv.utils.viz.plot_bbox(img, bounding_boxes[0], scores[0],\n",
    "                         class_IDs[0], class_names=net.classes)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试结果总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 148/149 [00:12<00:00, 11.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Throughput is 12.021019 img/sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "from gluoncv.data.batchify import Tuple, Stack, Pad\n",
    "from gluoncv.data.transforms.presets.yolo import YOLO3DefaultTrainTransform\n",
    "\n",
    "def validate(net, test_dataset, ctx):\n",
    "    if isinstance(ctx, mx.Context):\n",
    "        ctx = [ctx]\n",
    "    size = len(test_dataset)\n",
    "    metric = gcv.utils.metrics.voc_detection.VOC07MApMetric(iou_thresh=0.5, class_names=test_dataset.classes)\n",
    "    net.collect_params().reset_ctx(ctx)\n",
    "    metric.reset()\n",
    "    width, height = 512, 512\n",
    "    batch_size = 4\n",
    "    batchify_fn = Tuple(Stack(), Pad(pad_val=-1))\n",
    "    val_loader = mx.gluon.data.DataLoader(\n",
    "        test_dataset.transform(YOLO3DefaultTrainTransform(width, height)), batchify_fn=batchify_fn,\n",
    "        batch_size=batch_size, shuffle=False, last_batch='rollover', num_workers=0)\n",
    "    with tqdm(total=size) as pbar:\n",
    "        start = time.time()\n",
    "        for ib, batch in enumerate(val_loader):\n",
    "            data = mx.gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "            label = mx.gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "            det_bboxes = []\n",
    "            det_ids = []\n",
    "            det_scores = []\n",
    "            gt_bboxes = []\n",
    "            gt_ids = []\n",
    "            gt_difficults = []\n",
    "            for x, y in zip(data, label):\n",
    "                ids, scores, bboxes = net(x)\n",
    "                det_ids.append(ids)\n",
    "                det_scores.append(scores)\n",
    "                # clip to image size\n",
    "                det_bboxes.append(bboxes.clip(0, batch[0].shape[2]))\n",
    "                # split ground truths\n",
    "                gt_ids.append(y.slice_axis(axis=-1, begin=4, end=5))\n",
    "                gt_bboxes.append(y.slice_axis(axis=-1, begin=0, end=4))\n",
    "                gt_difficults.append(y.slice_axis(axis=-1, begin=5, end=6) if y.shape[-1] > 5 else None)\n",
    "\n",
    "            metric.update(det_bboxes, det_ids, det_scores, gt_bboxes, gt_ids, gt_difficults)\n",
    "            pbar.update(batch[0].shape[0])\n",
    "        end = time.time()\n",
    "        speed = size / (end - start)\n",
    "        print('Throughput is %f img/sec.'% speed)\n",
    "    return metric.get()\n",
    "\n",
    "final_result = validate(net, test_dataset, mx.gpu(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cocacola : 0.9090909090909093\n",
      "noodles : 0.9883040935672517\n",
      "hand : 0.9042482238654488\n",
      "fake : nan\n",
      "mAP : 0.93388107550787\n"
     ]
    }
   ],
   "source": [
    "for name, score in zip(*final_result):\n",
    "    print(name, ':', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
